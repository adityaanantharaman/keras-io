{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Conditional GAN\n",
    "\n",
    "**Author:** Aditya Anantharaman [twitter:ady_anr_]<br>\n",
    "**Date created:** 2020/10/21<br>\n",
    "**Last modified:** 2020/10/21<br>\n",
    "**Description:** Conditional gan using BCE loss trained on MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Training a Conditional GAN using BCE-loss on the MNIST-Dataset\n",
    "Conditional gans differ from normal dc-gans in that the class of the generated images can\n",
    "also be controlled. This feature is called controllable generation and is achieved by\n",
    "training both the discriminator and generator with labeled data as opposed to the\n",
    "unlabeled data used to train normal dc-gans. The main distinction here, is that the\n",
    "discriminator in addition to predicting wheather or not the generated image is a real\n",
    "looking image in general, also checks if it is a real looking image of that particular\n",
    "class. How the labels are used in the training of the discriminator and generator is\n",
    "discussed later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## loading and preprocessing the mnist dataset\n",
    "Make note to include the labels as well here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "(xtr, ytr), (_, _) = mnist.load_data()\n",
    "xtr = np.expand_dims(xtr, -1)\n",
    "xtr = xtr / 255.0  # bring the pixel values to the range 0 to 1\n",
    "xtr = (xtr - 0.5) / 0.5  # bring pixel values to range -1 to 1\n",
    "print(\n",
    "    \"shape of training images: \" + str(xtr.shape), \"shape of labels: \" + str(ytr.shape)\n",
    ")\n",
    "\n",
    "traindata = tf.data.Dataset.from_tensor_slices((xtr, ytr)).batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# How the labels play a role :\n",
    "### Generator :\n",
    "The generaotor takes in an input noise vector and generates an image. Here, the input\n",
    "noise vector, and the desired class' one-hot encoding vector are concatenated, and this\n",
    "is then fed into the generator in order to generate images of that particular class.\n",
    "### Discriminator\n",
    "In the discriminator on the other hand, the labels can be inserted into the training\n",
    "process in multiple ways. Here, we add the label info into the channel-dimension of the\n",
    "images fed into the discriminator. eg: the black and white mnist images have 1 channel.\n",
    "The one-hot label vector is tiled into 28x28 shape using 'tf.tile' and concatenated with\n",
    "the images along the 3rd dimension (channels). After tiling, if the label is of class 2,\n",
    "then the 2nd channel alone will consist of all ones, while all the other 9 channels\n",
    "consist of all zeros. This might be hard to grasp at first, but the implementation is\n",
    "really simple and will help understand the concept better. Thus, a 28x28x1 image is\n",
    "transformed into a 28x28x11 image in this case where the number of classes is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## create generator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_generator():\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                7 * 7 * 128, input_shape=(20,)\n",
    "            ),  # noise vector of length 10 and the one-hot encoding of the class of length 10\n",
    "            tf.keras.layers.Reshape((7, 7, 128)),\n",
    "            tf.keras.layers.Conv2DTranspose(64, 3, 2, padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2DTranspose(32, 3, 2, \"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.ReLU(),\n",
    "            tf.keras.layers.Conv2DTranspose(1, 4, 1, padding=\"same\", activation=\"tanh\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "gen = get_generator()\n",
    "gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## create discriminator architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_discriminator():\n",
    "    return tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                16, 3, 2, padding=\"same\", input_shape=(28, 28, 11)\n",
    "            ),  # label info concatenated with the image\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Conv2D(32, 3, 2, padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Conv2D(64, 3, 2, padding=\"same\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "dis = get_discriminator()\n",
    "dis.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## function for concatination of tensors about an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def combine_vectors(x, y, a):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    y = tf.cast(y, tf.float32)\n",
    "    return tf.concat([x, y], a)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## get one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def getoh(x):\n",
    "    return tf.one_hot(x, 10)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## setup optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "genopt = tf.keras.optimizers.Adam(0.0002, 0.5, 0.999)\n",
    "disopt = tf.keras.optimizers.Adam(0.0002, 0.5, 0.999)\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## print grid of 25 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def showout(x):\n",
    "    x = (x + 1) / 2.0\n",
    "    # x = np.array(x, dtype=np.uint8)\n",
    "    # x = (x).astype(np.uint8)\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    p = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        fig.add_subplot(5, 5, p + 1)\n",
    "        plt.imshow(x[i][:, :, 0].numpy().astype(np.uint8), cmap=\"gray\")\n",
    "        p += 1\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "generated = gen(tf.random.normal((25, 20)))\n",
    "print(generated.shape)\n",
    "showout(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "genlosses = []\n",
    "dislosses = []\n",
    "iteration = 0\n",
    "for e in range(10):\n",
    "    for realdata in tqdm(traindata):\n",
    "        realx = realdata[0]  # real images\n",
    "        labels = realdata[1]  # labels of real images\n",
    "        labels_oh = getoh(labels)\n",
    "        # get one hot encoding of labels for input to generator\n",
    "        curbatchsize = len(realx)\n",
    "        label_channels = tf.tile(\n",
    "            np.reshape(labels_oh, (curbatchsize, 1, 1, 10)), [1, 28, 28, 1]\n",
    "        )\n",
    "        # create tiled one-hot channels for discriminator input\n",
    "        # one-hot labels are first reshaped from (batch-size, 10) into (batch-size, 1, 1, 10)\n",
    "        # then this is tiled along the 2nd and 3rd dimensions to the size 28x28\n",
    "\n",
    "        with tf.GradientTape() as distape:  # updating discriminator\n",
    "            noise1 = tf.random.normal((curbatchsize, 10))\n",
    "            inputvec1 = combine_vectors(noise1, labels_oh, 1)\n",
    "\n",
    "            fakeimages1 = gen(inputvec1)\n",
    "            realimages1 = realx\n",
    "\n",
    "            f1 = combine_vectors(fakeimages1, label_channels, -1)\n",
    "            # concatenate label_channels to fake images and real images\n",
    "            r1 = combine_vectors(realimages1, label_channels, -1)\n",
    "\n",
    "            fouts = dis(f1)\n",
    "            routs = dis(r1)\n",
    "\n",
    "            floss = bce(tf.zeros_like(fouts), fouts)\n",
    "            rloss = bce(tf.ones_like(routs), routs)\n",
    "\n",
    "            disloss = (floss + rloss) / 2\n",
    "\n",
    "            disgrads = distape.gradient(disloss, dis.trainable_variables)\n",
    "\n",
    "            disopt.apply_gradients(zip(disgrads, dis.trainable_variables))\n",
    "\n",
    "        with tf.GradientTape() as gentape:  # updating generator\n",
    "            noise2 = tf.random.normal((curbatchsize, 10))\n",
    "            inputvec2 = combine_vectors(noise2, labels_oh, 1)\n",
    "            fakeimages2 = gen(inputvec2)\n",
    "            f2 = combine_vectors(fakeimages2, label_channels, -1)\n",
    "            fouts2 = dis(f2)\n",
    "            genloss = bce(tf.ones_like(fouts2), fouts2)\n",
    "            gengrads = gentape.gradient(genloss, gen.trainable_variables)\n",
    "            genopt.apply_gradients(zip(gengrads, gen.trainable_variables))\n",
    "\n",
    "        genlosses.append(genloss)\n",
    "        dislosses.append(disloss)\n",
    "        iteration += 1\n",
    "        if iteration % 500 == 0:\n",
    "            # every 100 iterations, generate using a custom label-vector = CONTROLABLE GENERATION\n",
    "            consta = tf.constant(\n",
    "                [\n",
    "                    0,\n",
    "                    1,\n",
    "                    2,\n",
    "                    3,\n",
    "                    4,\n",
    "                    5,\n",
    "                    6,\n",
    "                    7,\n",
    "                    8,\n",
    "                    9,\n",
    "                    0,\n",
    "                    1,\n",
    "                    2,\n",
    "                    3,\n",
    "                    4,\n",
    "                    5,\n",
    "                    6,\n",
    "                    7,\n",
    "                    8,\n",
    "                    9,\n",
    "                    0,\n",
    "                    1,\n",
    "                    2,\n",
    "                    3,\n",
    "                    4,\n",
    "                ]\n",
    "            )\n",
    "            noise3 = tf.random.normal((25, 10))\n",
    "            oh = getoh(consta)\n",
    "            inputvec3 = combine_vectors(noise3, oh, 1)\n",
    "            fakeimages3 = gen(inputvec3)\n",
    "            showout(fakeimages3)\n",
    "            plt.plot(dislosses)\n",
    "            plt.plot(genlosses)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Generating a GIF\n",
    "of transitioning between the different classes by manipulation of the latent vector.\n",
    "generate images from intermediate latent representations and convert the images into a\n",
    "gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "consta = tf.constant(\n",
    "    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4]\n",
    ")\n",
    "noise3 = tf.random.normal((25, 10))\n",
    "oh = getoh(consta)\n",
    "inputvec3 = combine_vectors(noise3, oh, 1)\n",
    "fakeimages3 = gen(inputvec3)\n",
    "showout(fakeimages3)\n",
    "\n",
    "aa = inputvec3.numpy()\n",
    "aa.shape\n",
    "\n",
    "bb = []\n",
    "for i in range(1, len(aa)):\n",
    "    start = aa[i - 1]\n",
    "    end = aa[i]\n",
    "    inc = (end - start) / 8\n",
    "    for i in range(8):\n",
    "        bb.append(start + i * inc)\n",
    "bb = np.array(bb)\n",
    "print(bb.shape)\n",
    "\n",
    "generated_images = gen(bb)\n",
    "generated_images.shape\n",
    "\n",
    "showout(generated_images[:25])\n",
    "\n",
    "import imageio\n",
    "\n",
    "imageio.mimsave(\"./movie.gif\", generated_images.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "conditional_gan",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}